{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-03 20:58:27,398 - RelationshipScorerPackage - INFO - Logging initialized. Level: INFO. Outputting to console only.\n"
     ]
    }
   ],
   "source": [
    "from src.main_scorer import RelationshipScorer\n",
    "# Import specific exceptions for more granular error handling if needed\n",
    "from src.exceptions import InputValidationError, ConfigurationError, CalculationError, ScoringInitializationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare your input data dictionary\n",
    "# This structure MUST conform to the ScorerInputData Pydantic model.\n",
    "# See config/data_model_config.yaml for a detailed example.\n",
    "input_data = {\n",
    "    \"relationship_mentions\": [\n",
    "        {\"source_type\": \"Guideline\", \"year\": 2025, \"sentiment\": \"Positive\", \"mention_id\": \"guideline-abc\"},\n",
    "        {\"source_type\": \"Label\", \"year\": 2023, \"sentiment\": \"Positive\", \"mention_id\": \"label-abc\"},\n",
    "        {\"source_type\": \"Phase 3 CT\", \"year\": 2021, \"sentiment\": \"Positive\", \"mention_id\": \"NCT12345\"},\n",
    "        {\"source_type\": \"Phase 2 CT\", \"year\": 2017, \"sentiment\": \"Positive\", \"mention_id\": \"NCT12345\"},\n",
    "        {\"source_type\": \"Phase 1 CT\", \"year\": 2015, \"sentiment\": \"Positive\", \"mention_id\": \"NCT12345\"},\n",
    "        {\"source_type\": \"PubMed\", \"year\": 2012, \"sentiment\": \"Neutral\", \"mention_id\": \"pmid:30000001\"},\n",
    "        {\"source_type\": \"PubMed\", \"year\": 2010, \"sentiment\": \"Negative\", \"mention_id\": \"pmid:30000000\"},\n",
    "        {\"source_type\": \"Review\", \"year\": 2005, \"sentiment\": \"Positive\", \"mention_id\": \"review-xyz\"}\n",
    "        # Add all relevant mentions for the specific entity pair\n",
    "    ],\n",
    "    \"entity_a_metadata\": {\n",
    "        \"id\": \"DRUG_X\",\n",
    "        # This score must be pre-calculated based on your entire dataset\n",
    "        \"overall_prominence\": 250.5\n",
    "    },\n",
    "    \"entity_b_metadata\": {\n",
    "        \"id\": \"DISEASE_Y\",\n",
    "        # This score must be pre-calculated based on your entire dataset\n",
    "        \"overall_prominence\": 180.0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing scorer...\n",
      "2025-04-03 20:58:27,411 - RelationshipScorerPackage - INFO - Initializing RelationshipScorer for entity pair: DRUG_X - DISEASE_Y\n",
      "2025-04-03 20:58:27,412 - RelationshipScorerPackage - INFO - Configuration loaded successfully.\n",
      "2025-04-03 20:58:27,412 - RelationshipScorerPackage - INFO - RelationshipScorer initialized successfully.\n",
      "Scorer initialized.\n",
      "Calculating all scores...\n",
      "2025-04-03 20:58:27,413 - RelationshipScorerPackage - INFO - Calculating all ensemble scores for DRUG_X - DISEASE_Y...\n",
      "2025-04-03 20:58:27,413 - RelationshipScorerPackage - INFO - Calculating Evidence Strength score...\n",
      "2025-04-03 20:58:27,413 - RelationshipScorerPackage - INFO - Evidence Strength calculation complete. Score: 6.345793429984428\n",
      "2025-04-03 20:58:27,413 - RelationshipScorerPackage - INFO - Calculating Sentiment scores...\n",
      "2025-04-03 20:58:27,413 - RelationshipScorerPackage - INFO - Sentiment score calculation complete. Dominant: Positive, Net: 34.50\n",
      "2025-04-03 20:58:27,414 - RelationshipScorerPackage - INFO - Calculating all Trend scores...\n",
      "2025-04-03 20:58:27,414 - RelationshipScorerPackage - INFO - EvidenceProgression calculation complete. Score: 5.00\n",
      "2025-04-03 20:58:27,415 - RelationshipScorerPackage - INFO - All trend scores calculated: {'recency_weighted': 22.681079401554523, 'rate_of_change': 20.0, 'evidence_progression': 5.0}\n",
      "2025-04-03 20:58:27,415 - RelationshipScorerPackage - INFO - Successfully calculated and validated all scores.\n",
      "\n",
      "--- All Scores ---\n",
      "{\n",
      "  \"evidence_strength\": 6.345793429984428,\n",
      "  \"sentiment_scores\": {\n",
      "    \"positive_score\": 35.5,\n",
      "    \"negative_score\": 1.0,\n",
      "    \"neutral_score\": 1.0,\n",
      "    \"net_score\": 34.5,\n",
      "    \"dominant_sentiment\": \"Positive\"\n",
      "  },\n",
      "  \"trend_scores\": {\n",
      "    \"recency_weighted\": 22.681079401554523,\n",
      "    \"rate_of_change\": 20.0,\n",
      "    \"evidence_progression\": 5.0\n",
      "  }\n",
      "}\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 2. Initialize the scorer and calculate scores\n",
    "try:\n",
    "    # Initialization validates input using Pydantic and loads config from files\n",
    "    print(\"Initializing scorer...\")\n",
    "    scorer = RelationshipScorer(input_data=input_data)\n",
    "    print(\"Scorer initialized.\")\n",
    "\n",
    "    # Calculate all scores at once\n",
    "    print(\"Calculating all scores...\")\n",
    "    all_scores = scorer.get_all_scores()\n",
    "    print(\"\\n--- All Scores ---\")\n",
    "    # Pretty print the dictionary\n",
    "    import json\n",
    "    print(json.dumps(all_scores, indent=2))\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "    # Alternatively, calculate individual scores if needed\n",
    "    # print(\"\\nCalculating individual scores...\")\n",
    "    # evidence = scorer.get_evidence_strength()\n",
    "    # print(f\"Evidence Strength: {evidence:.3f}\")\n",
    "    #\n",
    "    # sentiment = scorer.get_sentiment_scores()\n",
    "    # print(\"Sentiment Scores:\", sentiment)\n",
    "    #\n",
    "    # trend = scorer.get_trend_score()\n",
    "    # print(f\"Trend Score: {trend:.3f}\")\n",
    "\n",
    "except InputValidationError as e:\n",
    "    print(f\"\\nERROR: Input data is invalid.\")\n",
    "    print(f\"Details: {e.details}\") # Pydantic validation error details\n",
    "except ConfigurationError as e:\n",
    "    print(f\"\\nERROR: Configuration problem.\")\n",
    "    print(f\"Details: {e}\")\n",
    "except CalculationError as e:\n",
    "    print(f\"\\nERROR: Problem during score calculation.\")\n",
    "    print(f\"Details: {e}\")\n",
    "except ScoringInitializationError as e:\n",
    "    print(f\"\\nERROR: Failed to initialize the scorer.\")\n",
    "    print(f\"Details: {e}\")\n",
    "except Exception as e:\n",
    "    # Catch any other unexpected errors\n",
    "    print(f\"\\nAn unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
